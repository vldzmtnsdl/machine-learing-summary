{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 공룡책 chapter2: 사이킷런으로 시작하는 머신러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.사이킷런 소개와 특징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.첫번째 머신러닝 만들어보기-붓꽃 품종 예측하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.datasets: 데이터 세트를 생성하는 모듈의 모임. <br/> sklearn.tree: 트리기반 ML알고리즘을 구현한 클래스의 모임.<br/>\n",
    "sklearn.model_selection: 학습데이터와 검증 데이터, 예측데이터로 데이터를 분리하거나 최적의 하이퍼 파라미터로 평가하기 위한 다양한 모듈의 모임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data=iris.data\n",
    "iris_label=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print('iris target값:',iris_label)\n",
    "print('iris target명:',iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df=pd.DataFrame(data=iris_data,columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 데이터와 테스트용 데이터 분리\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris_data,iris_label,test_size=0.2,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier 객체 생성\n",
    "dt_clf=DecisionTreeClassifier(random_state=11)\n",
    "#학습 수행\n",
    "dt_clf.fit(X_train,y_train)\n",
    "#학습이 완료된 dt_clf 객체에서 테스트 데이터 세트로 예측 수행\n",
    "pred=dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측성능평가\n",
    "여러가지가 있으나 여기서는 **정확도**로 측정. <br/>예측결과가 실제 레이블 값과 얼마나 정확하게 맞는지를 평가하는\n",
    "지표."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.933333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도: {0:4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정리\n",
    "1. 데이터 세트 분리 <br/>\n",
    "2. 모델 학습 <br/>\n",
    "3. 예측 수행 <br/>\n",
    "4. 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 사이킷런의 기반 프레임워크 익히기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지도학습의 주요 두축인 분류와 회귀의 다양한 알고리즘을 구현한 모든 사이킷런 클래스는 fit()과 predict()만을\n",
    "이용해 간단하게 학습과 예측결과를 반환. <br/>\n",
    "분류(classifier)와 회귀(regressor)를 합쳐서 estimator클래스라고 부름. <br/>\n",
    "지도학습의 모든 알고리즘을 구현한 클래스를 통칭해서 estimator라고 부름. <br/>\n",
    "당연히 estimator 클래스는 fit()과 predict()를 내부에서 구현."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비지도학습에는 차원 축소, 클러스터링, 피처추출등의 클래스가 있음.\n",
    "이들은 fit(), transform()메서드를 적용.<br/>\n",
    "동시에 수행하는 fit_transform() 메서드도 있음<br/>\n",
    "다만 비지도학습의 fit()은 지도학습에서의 학습과 같은 개념이 아니라 데이터의 형태에 맞춰 데이터를 변환하기 위한 사전구조를 맞추는 작업을 의미."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 내장된 데이터세트의 형태\n",
    "딕셔너리 형태로 구성됨 <br/>\n",
    "data(ndarray),target(ndarray), target_name(ndarray/list),feature_names(ndarray/list),DESCR(str)로 구성됨 <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_data=load_iris()\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " bunch 클래스는 파이썬 딕셔너리 자료형과 유사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "keys=iris_data.keys()\n",
    "print('붓꽃 데이터 세트의 키들:',keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  model selection모듈 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습/테스트 데이터 세트 분리-train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris=load_iris()\n",
    "dt_clf=DecisionTreeClassifier()\n",
    "train_data=iris.data\n",
    "train_label=iris.target\n",
    "dt_clf.fit(train_data,train_label)\n",
    "\n",
    "pred=dt_clf.predict(train_data)\n",
    "print('예측 정확도:',accuracy_score(train_label,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 정확도가 100%인 이유는 이미 학습한 학습 데이터 세트를 기반으로 예측했기 때문.\n",
    "train_test_split필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dt_clf=DecisionTreeClassifier()\n",
    "X_train,X_test,y_train,y_test=train_test_split(train_data,train_label,test_size=0.3,random_state=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "dt_clf.fit(X_train,y_train)\n",
    "pred=dt_clf.predict(X_test)\n",
    "print('예측 정확도:',accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차검증\n",
    "\n",
    "교차검증이 필요한 이유: 고정된 학습 데이터와 테스트 데이터로 평가를 하다 보면 테스트 데이터에만 과적합되는\n",
    "학습 모델이 만들어져 다른 테스트용 데이터가 들어올 경우에는 성능이 저하됨.<br/>\n",
    "따라서 **여러세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평과를 수행해야함.**<br/>\n",
    "=> 학습, 검증, 테스트 데이터 구분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k폴드 교차검증: k개의 데이터 폴드 세트를 만들어서 k번만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기: 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "features=iris.data\n",
    "label=iris.target\n",
    "dt_clf=DecisionTreeClassifier(random_state=156)\n",
    "kfold=KFold(n_splits=5)\n",
    "cv_accuracy=[]\n",
    "print('붓꽃 데이터 세트 크기:',features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k폴드 구현 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stratified k 폴드: k폴드가 레이블 데이터 집합이 원본 데이터 집합의 레이블 분포를 학습 및 테스트 세트에 제대로 분배하지 못하는 경우의 문제를 해결. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차검증: 1\n",
      "학습 레이블 분포:\n",
      " 2    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 분포:\n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "## 교차검증: 2\n",
      "학습 레이블 분포:\n",
      " 2    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 분포:\n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "## 교차검증: 3\n",
      "학습 레이블 분포:\n",
      " 1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 분포:\n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 이슈가 발생하는 현상\n",
    "kfold=KFold(n_splits=3)\n",
    "n_iter=0\n",
    "for train_index,test_index in kfold.split(iris_df):\n",
    "    n_iter+=1\n",
    "    label_train=iris_df['label'].iloc[train_index]\n",
    "    label_test=iris_df['label'].iloc[test_index]\n",
    "    print('## 교차검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 분포:\\n',label_train.value_counts())\n",
    "    print('검증 레이블 분포:\\n',label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " 2    34\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    17\n",
      "0    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " 1    34\n",
      "2    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    17\n",
      "0    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    34\n",
      "2    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    17\n",
      "1    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#stratified kfold \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_iter=0\n",
    "skf=StratifiedKFold(n_splits=3)\n",
    "for train_index,test_index in skf.split(iris.data,iris.target):\n",
    "    n_iter+=1\n",
    "    label_train=iris_df['label'].iloc[train_index]\n",
    "    label_test=iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n',label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n',label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "0.92\n",
      "0.98\n",
      "[0.98 0.92 0.98]\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "#stratified kfold \n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_iter=0\n",
    "cv_accuracy=[]\n",
    "skf=StratifiedKFold(n_splits=3)\n",
    "for train_index,test_index in skf.split(iris.data,iris.target):\n",
    "    n_iter+=1\n",
    "    dt_clf=DecisionTreeClassifier()\n",
    "    X_train,X_test=features[train_index],features[test_index]\n",
    "    y_train,y_test=label[train_index],label[test_index]\n",
    "    dt_clf.fit(X_train,y_train)\n",
    "    pred=dt_clf.predict(X_test)\n",
    "    accuracy=np.round(accuracy_score(y_test,pred),4)\n",
    "    print(accuracy)\n",
    "    cv_accuracy.append(accuracy)\n",
    "print(np.round(cv_accuracy,4))\n",
    "print(np.mean(cv_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#회귀(regressor)에서는 stratified kfold가 지원되지 않음. 회귀의 결정값은 연속형이기 때문에. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross_val_score() 한꺼번에 수행! 결과로 검증 정확도 리스트형태로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "평균 검증 정확도: 1.0 4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score,cross_validate\n",
    "\n",
    "iris_data=load_iris()\n",
    "dt_clf=DecisionTreeClassifier(random_state=156)\n",
    "data=iris_data.data\n",
    "label=iris_data.target\n",
    "\n",
    "scores=cross_val_score(dt_clf,data,label,scoring='accuracy',cv=3)\n",
    "print('교차 검증별 정확도:',np.round(scores,4))\n",
    "print('평균 검증 정확도:',np.round(np.mean(scores)),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV-교차검증과 최적 하이퍼 파라미터 튜닝을 한 번에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris=load_iris()\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris.data,iris.target,test_size=0.2,random_state=121)\n",
    "\n",
    "dtree=DecisionTreeClassifier()\n",
    "\n",
    "parameters={'max_depth':[1,2,3],'min_samples_split':[2,3]}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "grid_dtree=GridSearchCV(dtree,param_grid=parameters,cv=3,refit=True)\n",
    "grid_dtree.fit(X_train,y_train)\n",
    "scores_df=pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도:[0:4f].format(accuracy_score(y_test,pred))\n"
     ]
    }
   ],
   "source": [
    "estimator=grid_dtree.best_estimator_\n",
    "\n",
    "pred=estimator.predict(X_test)\n",
    "print('테스트 데이터 세트 정확도:[0:4f].format(accuracy_score(y_test,pred))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값: [0 1 4 5 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "# 레이블 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels=encoder.transform(items)\n",
    "print('인코딩 변환값:',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
     ]
    }
   ],
   "source": [
    "print('인코딩 클래스:',encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디코딩 원본값: ['전자레인지' '컴퓨터' '선풍기' '믹서']\n"
     ]
    }
   ],
   "source": [
    "print('디코딩 원본값:',encoder.inverse_transform([4,5,3,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 레이블 인코딩은 숫자의 중요도가 존재하는 회귀에는 사용하면 안됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "원핫 인코딩 데이터 차원\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "## 원-핫 인코딩\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels=encoder.transform(items)\n",
    "\n",
    "labels=labels.reshape(-1,1)\n",
    "\n",
    "oh_encoder=OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels=oh_encoder.transform(labels)\n",
    "print('원핫 인코딩 데이터')\n",
    "print(oh_labels.toarray())\n",
    "print('원핫 인코딩 데이터 차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items_TV</th>\n",
       "      <th>items_냉장고</th>\n",
       "      <th>items_믹서</th>\n",
       "      <th>items_선풍기</th>\n",
       "      <th>items_전자레인지</th>\n",
       "      <th>items_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   items_TV  items_냉장고  items_믹서  items_선풍기  items_전자레인지  items_컴퓨터\n",
       "0         1          0         0          0            0          0\n",
       "1         0          1         0          0            0          0\n",
       "2         0          0         0          0            1          0\n",
       "3         0          0         0          0            0          1\n",
       "4         0          0         0          1            0          0\n",
       "5         0          0         0          1            0          0\n",
       "6         0          0         1          0            0          0\n",
       "7         0          0         1          0            0          0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 한번에 수행\n",
    "df=pd.DataFrame({'items':['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 피처 스케일링(표준화,정규화)\n",
    "표준화-StandardScaler\n",
    "정규화-MInMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 평균값\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "feature  들의 분산값\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris=load_iris()\n",
    "iris_data=iris.data\n",
    "iris_df=pd.DataFrame(data=iris_data,columns=iris.feature_names)\n",
    "\n",
    "print('feature 들의 평균값')\n",
    "print(iris_df.mean())\n",
    "print('\\nfeature  들의 분산값')\n",
    "print(iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 평균값\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "feature들의 분산값\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled=scaler.transform(iris_df)\n",
    "iris_df_scaled=pd.DataFrame(iris_scaled,columns=iris.feature_names)\n",
    "print('feature들의 평균값')\n",
    "print(iris_df_scaled.mean())\n",
    "print('\\nfeature들의 분산값')\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 최솟값\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "feature들의 최대값\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler 데이터의 분포가 가우시안 분포가 아닐 경우에 min,max scale을 적용.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled=scaler.transform(iris_df)\n",
    "\n",
    "iris_df_scaled=pd.DataFrame(iris_scaled,columns=iris.feature_names)\n",
    "print('feature들의 최솟값')\n",
    "print(iris_df_scaled.min())\n",
    "print('feature들의 최대값')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0           0.222222          0.625000           0.067797          0.041667\n",
       "1           0.166667          0.416667           0.067797          0.041667\n",
       "2           0.111111          0.500000           0.050847          0.041667\n",
       "3           0.083333          0.458333           0.084746          0.041667\n",
       "4           0.194444          0.666667           0.067797          0.041667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df_scaled.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습데이터와 테스트데이터의 스케일링 변환 시 유의점\n",
    "학습데이터로 fit된 scaler로 테스트데이터를 transform 시켜야함.\n",
    "테스트 데이터로 scaler를 다시 fit 시키면 안됨.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scaled 된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_array=np.arange(0,11).reshape(-1,1)\n",
    "test_array=np.arange(0,6).reshape(-1,1)\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "\n",
    "train_scaled=scaler.transform(train_array)\n",
    "print('원본 train_array 데이터:',np.round(train_array.reshape(-1),2))\n",
    "print('Scaled 된 train_array 데이터:',np.round(train_scaled.reshape(-1),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 test_array 데이터: [0 1 2 3 4 5]\n",
      "Scaled 된 test_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "test_scaled=scaler.transform(test_array)\n",
    "print('원본 test_array 데이터:',np.round(test_array.reshape(-1),2))\n",
    "print('Scaled 된 test_array 데이터:',np.round(test_scaled.reshape(-1),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
